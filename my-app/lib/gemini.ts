import { GoogleGenAI } from "@google/genai";

const MODEL = "gemini-3-flash-preview";
const IMAGE_MODEL = "gemini-3-pro-image-preview"; // nano-banana-3-pro

// Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„±
function getGeminiClient(): GoogleGenAI {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) {
    throw new Error("GEMINI_API_KEY is not configured");
  }
  return new GoogleGenAI({ apiKey });
}

// JSON ì¶”ì¶œ í•¨ìˆ˜ - ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSONë§Œ ì¶”ì¶œ
export function extractJSON(text: string): object {
  // ë¨¼ì € ì „ì²´ í…ìŠ¤íŠ¸ê°€ JSONì¸ì§€ í™•ì¸
  try {
    return JSON.parse(text);
  } catch {
    // JSON ë¸”ë¡ì„ ì°¾ì•„ì„œ ì¶”ì¶œ (```json ... ``` í˜•ì‹ í¬í•¨)
    const jsonBlockMatch = text.match(/```(?:json)?\s*([\s\S]*?)```/);
    if (jsonBlockMatch) {
      try {
        return JSON.parse(jsonBlockMatch[1].trim());
      } catch {
        // ê³„ì† ì‹œë„
      }
    }

    // ì¼ë°˜ JSON ê°ì²´ ì¶”ì¶œ
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      try {
        return JSON.parse(jsonMatch[0]);
      } catch {
        // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
      }
    }
  }
  return {};
}

// ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±
export async function generateContent(
  prompt: string,
  systemPrompt?: string
): Promise<string> {
  const ai = getGeminiClient();

  const fullPrompt = systemPrompt
    ? `${systemPrompt}\n\n---\n\n${prompt}`
    : prompt;

  const response = await ai.models.generateContent({
    model: MODEL,
    contents: fullPrompt,
  });

  return response.text || "";
}

// ë‰´ìŠ¤ ìš”ì•½ ê¸°ëŠ¥
export interface SummarizeResult {
  headline: string;
  bullets: string[];
  insight: string;
  category: string;
  wowFactor?: {
    description: string;
    suggestedMedia: string;
  };
}

export async function summarizeNews(
  title: string,
  content: string
): Promise<SummarizeResult> {
  const ai = getGeminiClient();

  const systemPrompt = `ë‹¹ì‹ ì€ AI/ML/LLM ë¶„ì•¼ ì „ë¬¸ í…Œí¬ ì½˜í…ì¸  ë¼ì´í„°ì…ë‹ˆë‹¤. AI ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì½ê³  ë…ìë“¤ì´ "ì´ê²Œ ì™œ ì¤‘ìš”í•˜ì§€?"ë¼ëŠ” ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

## ì½˜í…ìŠ¤íŠ¸
- ì´ ë‰´ìŠ¤ëŠ” AI, ë¨¸ì‹ ëŸ¬ë‹, LLM, ìƒì„±í˜• AI ê´€ë ¨ ì†Œì‹ì…ë‹ˆë‹¤
- ë…ìëŠ” AI/í…Œí¬ì— ê´€ì‹¬ìˆëŠ” í•œêµ­ì–´ ì‚¬ìš©ìì…ë‹ˆë‹¤

## ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼
- ë¬´ì—‡ì´ ê³µê°œ/ë°œí‘œë˜ì—ˆëŠ”ì§€ ëª…í™•í•˜ê²Œ ì„¤ëª…
- ê¸°ì¡´ê³¼ ë¬´ì—‡ì´ ë‹¬ë¼ì§€ëŠ”ì§€ ë¹„êµ
- ì—…ê³„/ì‚¬ìš©ìì—ê²Œ ë¯¸ì¹˜ëŠ” ì‹¤ì§ˆì  ì„íŒ©íŠ¸ ë¶„ì„
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…

## ì¤‘ìš”: ê³ ìœ ëª…ì‚¬ ì²˜ë¦¬
- íšŒì‚¬ëª…, ì œí’ˆëª…, ëª¨ë¸ëª…, ì¸ëª…ì€ **ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€** (ë²ˆì—­ ê¸ˆì§€)
- ì˜ˆì‹œ: OpenAI, Claude, GPT-4, Gemini, Meta, Google, Anthropic, Llama, Mistral, Sam Altman ë“±
- ê¸°ìˆ  ìš©ì–´ë„ ì›ë¬¸ ìœ ì§€: API, GPU, TPU, transformer, fine-tuning, RAG, embedding ë“±

ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.`;

  const userPrompt = `ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ì½˜í…ì¸  ë¼ì´í„° ê´€ì ì—ì„œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

ì œëª©: ${title}
ë‚´ìš©: ${content.substring(0, 3000)}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "headline": "í•œ ì¤„ë¡œ í•µì‹¬ì„ ë‹´ì€ ì œëª© (20-40ì)",
  "bullets": [
    "ì²« ë²ˆì§¸ í¬ì¸íŠ¸: ë¬´ì—‡ì´ ì–´ë–»ê²Œ ê³µê°œ/ë³€ê²½ë˜ì—ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ (40-60ì)",
    "ë‘ ë²ˆì§¸ í¬ì¸íŠ¸: ê¸°ì¡´ ëŒ€ë¹„ ë¬´ì—‡ì´ ë‹¬ë¼ì§€ê³  ì™œ ì£¼ëª©í•  ë§Œí•œì§€ (40-60ì)",
    "ì„¸ ë²ˆì§¸ í¬ì¸íŠ¸: ì‚¬ìš©ì/ì—…ê³„ì— ë¯¸ì¹˜ëŠ” ì‹¤ì§ˆì  ì˜í–¥ê³¼ ì˜ë¯¸ (40-60ì)"
  ],
  "insight": "ì™œ ì´ ë‰´ìŠ¤ê°€ ì¤‘ìš”í•œì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ (50-80ì)",
  "category": "product|update|research|announcement|other ì¤‘ í•˜ë‚˜",
  "wowFactor": {
    "description": "ì´ ë‰´ìŠ¤ì—ì„œ ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ í¬ì¸íŠ¸ (30-50ì)",
    "suggestedMedia": "ì´ ë‰´ìŠ¤ë¥¼ ì‹œê°í™”í•  ë•Œ ì¶”ì²œí•˜ëŠ” ë¯¸ë””ì–´ ìœ í˜• (ì˜ˆ: ì œí’ˆ ìŠ¤í¬ë¦°ìƒ·, ë¹„êµ ì°¨íŠ¸, ì¸í¬ê·¸ë˜í”½ ë“±)"
  }
}`;

  const response = await ai.models.generateContent({
    model: MODEL,
    contents: `${systemPrompt}\n\n---\n\n${userPrompt}`,
    config: {
      temperature: 0.6,
    },
  });

  const result = extractJSON(response.text || "{}") as SummarizeResult;

  // ê¸°ë³¸ê°’ ì„¤ì •
  if (!result.headline) {
    result.headline = title;
  }
  if (!result.bullets || result.bullets.length === 0) {
    result.bullets = [
      `${title}ì— ëŒ€í•œ ìš”ì•½ì…ë‹ˆë‹¤.`,
      "ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.",
      "ì¶”ê°€ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
    ];
  }
  if (!result.insight) {
    result.insight = "ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”.";
  }
  if (!result.category) {
    result.category = "other";
  }

  return result;
}

// í”Œë«í¼ë³„ ì½˜í…ì¸  ìƒì„±
export interface PlatformContentResult {
  content: string;
  charCount: number;
  hashtags?: string[];
}

// í”Œë«í¼ë³„ ì„¤ì •
const platformConfigs: Record<
  string,
  { maxLength: number; description: string; style: string }
> = {
  twitter: {
    maxLength: 280,
    description: "X(íŠ¸ìœ„í„°)",
    style: `## í•µì‹¬
- í•œ ë¬¸ì¥ìœ¼ë¡œ ì„íŒ©íŠ¸ ìˆê²Œ
- ìˆ«ì/íŒ©íŠ¸ë¡œ ê´€ì‹¬ ìœ ë°œ
- ì´ëª¨ì§€ 1-2ê°œë§Œ

## í•´ì‹œíƒœê·¸
- 1-2ê°œ ìµœëŒ€
- ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨`,
  },
  threads: {
    maxLength: 500,
    description: "Threads",
    style: `## í†¤
- ëŒ€í™”ì²´, ì¹œê·¼í•˜ê²Œ
- ì˜ê²¬/ì¸ì‚¬ì´íŠ¸ í¬í•¨ ê°€ëŠ¥

## êµ¬ì¡°
- 2-3ë¬¸ë‹¨ìœ¼ë¡œ ì •ë³´ ì „ë‹¬
- ë¬¸ë‹¨ ì‚¬ì´ ì¤„ë°”ê¿ˆ
- ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ ëŒ“ê¸€ ìœ ë„
- í•´ì‹œíƒœê·¸ ë¶ˆí•„ìš” (ì„ íƒì )`,
  },
  instagram: {
    maxLength: 2200,
    description: "Instagram",
    style: `## í›… ë¼ì¸ (ì²« ì¤„ì´ í•µì‹¬!)
- í”¼ë“œì—ì„œ "...ë” ë³´ê¸°" ì „ì— ë³´ì´ëŠ” ìœ ì¼í•œ í…ìŠ¤íŠ¸
- í˜¸ê¸°ì‹¬ ìœ ë°œ/ì¶©ê²©ì  ì‚¬ì‹¤/ì§ˆë¬¸ í˜•ì‹
- ì˜ˆ: "ì´ê±° ì§„ì§œ ê²Œì„ì²´ì¸ì €ì…ë‹ˆë‹¤ ğŸ”¥"

## êµ¬ì¡°
1. í›… ë¼ì¸ (1ì¤„)
2. [ë¹ˆ ì¤„]
3. í•µì‹¬ ë‚´ìš© (1-2ë¬¸ë‹¨, ê° 1-2ë¬¸ì¥)
4. [ë¹ˆ ì¤„]
5. ì¸ì‚¬ì´íŠ¸/ì‹œì‚¬ì 
6. [ë¹ˆ ì¤„]
7. CTA: "ì €ì¥í•´ë‘ì„¸ìš” ğŸ’¾" ë˜ëŠ” "ì—¬ëŸ¬ë¶„ ìƒê°ì€? ğŸ’¬"

## í¬ë§·
- ë¬¸ë‹¨ = 1-2ë¬¸ì¥, ìµœëŒ€ 3ì¤„
- ë¬¸ë‹¨ ì‚¬ì´ ë¹ˆ ì¤„ í•„ìˆ˜ (ëª¨ë°”ì¼ ê°€ë…ì„±)
- ì´ëª¨ì§€: ë¬¸ì¥ ì‹œì‘/ì¤‘ê°„ì— ìì—°ìŠ¤ëŸ½ê²Œ (ëì— ëª°ì•„ë„£ê¸° ê¸ˆì§€)
- ì „ì²´ ì´ëª¨ì§€ 5-8ê°œ`,
  },
  linkedin: {
    maxLength: 3000,
    description: "LinkedIn",
    style: `## í†¤
- ì „ë¬¸ì , ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬
- ì—…ê³„ ì˜í–¥ ë¶„ì„ í¬í•¨

## êµ¬ì¡°
1. í•µì‹¬ ì†Œì‹ (1-2ë¬¸ì¥)
2. [ë¹ˆ ì¤„]
3. ì™œ ì¤‘ìš”í•œì§€ (2-3ë¬¸ë‹¨)
4. [ë¹ˆ ì¤„]
5. ì‹œì‚¬ì /ì „ë§
6. (ì„ íƒ) ì˜ê²¬ ìš”ì²­

## í¬ë§·
- ì§§ì€ ë¬¸ë‹¨
- ì´ëª¨ì§€ ìµœì†Œí™” (0-3ê°œ)
- í•´ì‹œíƒœê·¸ 3-5ê°œ (ì „ë¬¸ì )`,
  },
};

// Instagram ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
function getInstagramSystemPrompt(sourceName?: string): string {
  return `Instagram í…Œí¬ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.

## í›… ë¼ì¸ ì‘ì„±ë²• (ê°€ì¥ ì¤‘ìš”!)
í”¼ë“œì—ì„œ "...ë” ë³´ê¸°" ì „ì— ë³´ì´ëŠ” ì²« ì¤„ì´ í´ë¦­ì„ ê²°ì •í•©ë‹ˆë‹¤.
- í˜¸ê¸°ì‹¬ ìê·¹: "ì´ê±° ì•Œê³  ê³„ì…¨ë‚˜ìš”? ğŸ¤”"
- ì¶©ê²©ì  ì‚¬ì‹¤: "GPT-4ê°€ ë“œë””ì–´ 128K í† í°ì„ ì§€ì›í•©ë‹ˆë‹¤"
- ê°€ì¹˜ ì œì•ˆ: "ê°œë°œìë¼ë©´ ê¼­ ì•Œì•„ì•¼ í•  ì†Œì‹"
- ê°ì • ìœ ë°œ: "ì´ ì†Œì‹ ë³´ê³  ì†Œë¦„ ë‹ì•˜ìŠµë‹ˆë‹¤ ğŸ˜±"

## ëª¨ë°”ì¼ ê°€ë…ì„±
- í•œ ë¬¸ë‹¨ = 1-2ë¬¸ì¥ (ìµœëŒ€ 3ì¤„)
- ë¬¸ë‹¨ ì‚¬ì´ ë¹ˆ ì¤„ë¡œ êµ¬ë¶„ (í•„ìˆ˜!)
- ìŠ¤í¬ë¡¤í•˜ë©° ì‰½ê²Œ ì½íˆë„ë¡

## ì´ëª¨ì§€ ì‚¬ìš©ë²•
- ë¬¸ì¥ ì‹œì‘ ë˜ëŠ” ì¤‘ê°„ì— ìì—°ìŠ¤ëŸ½ê²Œ
- ëì— ëª°ì•„ë„£ì§€ ì•Šê¸°
- ì „ì²´ 5-8ê°œ ì ì •

## CTA (ë§ˆì§€ë§‰ì— í•˜ë‚˜ ì„ íƒ)
- "ì €ì¥í•´ë‘ë©´ ë‚˜ì¤‘ì— ìœ ìš©í•´ìš” ğŸ’¾"
- "ì—¬ëŸ¬ë¶„ ìƒê°ì€? ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš” ğŸ’¬"
- "ì•Œë ¤ì£¼ê³  ì‹¶ì€ ì¹œêµ¬ íƒœê·¸ ğŸ‘‡"

## ê·œì¹™
1. ê¸€ììˆ˜: 1100~1760ì (í•´ì‹œíƒœê·¸ ì œì™¸)
2. ê³ ìœ ëª…ì‚¬ ì›ë¬¸ ìœ ì§€ (OpenAI, GPT-4, Claude ë“±)
3. íŒ©íŠ¸ ì¤‘ì‹¬, ê³¼ì¥ ê¸ˆì§€
${sourceName ? `4. ë§ˆì§€ë§‰ì— "ì¶œì²˜: ${sourceName}" ì¶”ê°€` : ""}

JSONìœ¼ë¡œë§Œ ì‘ë‹µ.`;
}

// Instagram ì „ìš© ìœ ì € í”„ë¡¬í”„íŠ¸
function getInstagramUserPrompt(
  title: string,
  content: string,
  url?: string
): string {
  return `ë‹¤ìŒ AI/í…Œí¬ ë‰´ìŠ¤ë¥¼ Instagram ìº¡ì…˜ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:

ì œëª©: ${title}
ë‚´ìš©: ${content}
${url ? `ë§í¬: ${url}` : ""}

## ì‘ë‹µ í˜•ì‹
{
  "content": "ìº¡ì…˜ (í›… ë¼ì¸ìœ¼ë¡œ ì‹œì‘, ì¤„ë°”ê¿ˆ í¬í•¨, CTA í¬í•¨)",
  "charCount": ê¸€ììˆ˜,
  "hashtags": ["í•´ì‹œíƒœê·¸ë“¤ 8-15ê°œ"]
}

## í•´ì‹œíƒœê·¸ êµ¬ì„± (8-15ê°œ)
- ëŒ€ì¤‘ì  (3-4ê°œ): AI, Tech, Innovation, MachineLearning
- ì „ë¬¸ì  (3-4ê°œ): LLM, GPT, GenAI, MLOps, RAG
- í•œêµ­ì–´ (2-3ê°œ): ì¸ê³µì§€ëŠ¥, í…Œí¬ë‰´ìŠ¤, AIì†Œì‹, ë”¥ëŸ¬ë‹
- ì£¼ì œ ê´€ë ¨ (2-3ê°œ): ë‰´ìŠ¤ ë‚´ìš©ì— ë§ê²Œ`;
}

export async function generatePlatformContent(
  title: string,
  content: string,
  platform: string,
  url?: string,
  sourceName?: string
): Promise<PlatformContentResult> {
  const ai = getGeminiClient();

  const config = platformConfigs[platform];
  if (!config) {
    throw new Error(`Invalid platform: ${platform}`);
  }

  let systemPrompt: string;
  let userPrompt: string;

  if (platform === "instagram") {
    // Instagram ì „ìš© í”„ë¡¬í”„íŠ¸
    systemPrompt = getInstagramSystemPrompt(sourceName);
    userPrompt = getInstagramUserPrompt(title, content, url);
  } else {
    // ë‹¤ë¥¸ í”Œë«í¼ìš© ê³µí†µ í”„ë¡¬í”„íŠ¸ (ê°œì„ ëœ style í¬í•¨)
    systemPrompt = `í…Œí¬ ë‰´ìŠ¤ë¥¼ ì†Œì…œ ë¯¸ë””ì–´ìš©ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.

## ì‘ì„± ìŠ¤íƒ€ì¼
- ì •ë³´ ì „ë‹¬ ì¤‘ì‹¬, êµ°ë”ë”ê¸° ì—†ì´
- ì´ëª¨ì§€ëŠ” í•„ìš”í• ë•Œ í¬ì¸íŠ¸ì—ë§Œ ì ì ˆíˆ
${sourceName ? `- ë§ˆì§€ë§‰ì— "ì¶œì²˜: ${sourceName}" ì¶”ê°€` : ""}

## ê·œì¹™
1. íŒ©íŠ¸ ì¤‘ì‹¬ (ìˆ«ì, ì´ë¦„, ì‚¬ì‹¤ê´€ê³„ ì •í™•íˆ)
2. ${Math.floor(config.maxLength * 0.5)}~${Math.floor(config.maxLength * 0.8)}ì
3. ê³ ìœ ëª…ì‚¬ ì›ë¬¸ ìœ ì§€

## ${config.description} ê°€ì´ë“œë¼ì¸
${config.style}

JSONìœ¼ë¡œë§Œ ì‘ë‹µ.`;

    userPrompt = `ì´ ë‰´ìŠ¤ë¥¼ ${config.description} í¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤˜:

ì œëª©: ${title}
ë‚´ìš©: ${content}
${url ? `ë§í¬: ${url}` : ""}

{
  "content": "í¬ìŠ¤íŠ¸ ë‚´ìš©",
  "charCount": ê¸€ììˆ˜
}`;
  }

  const response = await ai.models.generateContent({
    model: MODEL,
    contents: `${systemPrompt}\n\n---\n\n${userPrompt}`,
    config: {
      temperature: 0.7,
    },
  });

  const result = extractJSON(response.text || "{}") as PlatformContentResult;

  // ê¸°ë³¸ê°’ ì„¤ì •
  if (!result.content) {
    result.content = `${title}\n\nìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.`;
  }
  if (!result.charCount) {
    result.charCount = result.content.length;
  }

  return result;
}

// ì½˜í…ì¸  ì¬ìƒì„±
export async function regenerateContent(
  previousContent: string,
  feedback: string,
  platform: string
): Promise<PlatformContentResult> {
  const ai = getGeminiClient();

  const config = platformConfigs[platform];
  const maxLength = config?.maxLength || 500;
  const description = config?.description || platform;

  // í”Œë«í¼ë³„ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
  const platformStyleGuide =
    platform === "instagram"
      ? `## Instagram ìŠ¤íƒ€ì¼
- í›… ë¼ì¸ìœ¼ë¡œ ì‹œì‘ (í˜¸ê¸°ì‹¬ ìœ ë°œ)
- ë¬¸ë‹¨ ì‚¬ì´ ë¹ˆ ì¤„ í•„ìˆ˜
- ì´ëª¨ì§€ëŠ” ë¬¸ì¥ ì¤‘ê°„ì— ìì—°ìŠ¤ëŸ½ê²Œ (ëì— ëª°ì•„ë„£ê¸° ê¸ˆì§€)
- ë§ˆì§€ë§‰ì— CTA í¬í•¨ ("ì €ì¥í•´ë‘ì„¸ìš” ğŸ’¾" ë“±)`
      : platform === "twitter"
        ? `## X(íŠ¸ìœ„í„°) ìŠ¤íƒ€ì¼
- í•œ ë¬¸ì¥ìœ¼ë¡œ ì„íŒ©íŠ¸ ìˆê²Œ
- ì´ëª¨ì§€ 1-2ê°œë§Œ
- í•´ì‹œíƒœê·¸ 1-2ê°œ`
        : platform === "threads"
          ? `## Threads ìŠ¤íƒ€ì¼
- ëŒ€í™”ì²´, ì¹œê·¼í•˜ê²Œ
- 2-3ë¬¸ë‹¨ìœ¼ë¡œ ì •ë³´ ì „ë‹¬
- ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬`
          : platform === "linkedin"
            ? `## LinkedIn ìŠ¤íƒ€ì¼
- ì „ë¬¸ì , ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬
- ì§§ì€ ë¬¸ë‹¨
- ì´ëª¨ì§€ ìµœì†Œí™”`
            : `## ê¸°ë³¸ ìŠ¤íƒ€ì¼
- 2-3ë¬¸ì¥ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ
- ì´ëª¨ì§€ëŠ” ë¬¸ì¥ ì¤‘ê°„ì— ìì—°ìŠ¤ëŸ½ê²Œ`;

  const systemPrompt = `í”¼ë“œë°± ë°˜ì˜í•´ì„œ ${description} ì½˜í…ì¸ ë¥¼ ìˆ˜ì •í•´ì¤˜.

${platformStyleGuide}

ê¸€ììˆ˜ ${Math.floor(maxLength * 0.5)}~${Math.floor(maxLength * 0.8)}ì. JSONìœ¼ë¡œë§Œ ì‘ë‹µ.`;

  const userPrompt = `ì›ë³¸:
${previousContent}

í”¼ë“œë°±: ${feedback}

{
  "content": "ìˆ˜ì •ëœ ë‚´ìš©",
  "charCount": ê¸€ììˆ˜${platform === "instagram" ? ',\n  "hashtags": ["ê¸°ì¡´ í•´ì‹œíƒœê·¸ ìœ ì§€ ë˜ëŠ” ìˆ˜ì •"]' : ""}
}`;

  const response = await ai.models.generateContent({
    model: MODEL,
    contents: `${systemPrompt}\n\n---\n\n${userPrompt}`,
    config: {
      temperature: 0.7,
    },
  });

  const result = extractJSON(response.text || "{}") as PlatformContentResult;

  // ê¸°ë³¸ê°’ ì„¤ì •
  if (!result.content) {
    result.content = previousContent;
  }
  if (!result.charCount) {
    result.charCount = result.content.length;
  }

  return result;
}

// ë²ˆì—­ ê¸°ëŠ¥
export interface TranslateResult {
  title: string;
  content: string;
  isTranslated: boolean;
}

export async function translateContent(
  title: string,
  content: string
): Promise<TranslateResult> {
  const ai = getGeminiClient();

  const trimmedContent = content.trim();
  if (trimmedContent.length < 20) {
    return {
      title: title || "",
      content: trimmedContent,
      isTranslated: false,
    };
  }

  const systemPrompt = `ë‹¹ì‹ ì€ AI/í…Œí¬ ë¶„ì•¼ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì›ë¬¸ì„ í•œêµ­ì–´ë¡œ **ì¶©ì‹¤í•˜ê²Œ ì§ì—­**í•©ë‹ˆë‹¤.

## ì½˜í…ìŠ¤íŠ¸
- ì´ ê¸°ì‚¬ëŠ” AI, ë¨¸ì‹ ëŸ¬ë‹, LLM, ìƒì„±í˜• AI ê´€ë ¨ í…Œí¬ ë‰´ìŠ¤ì…ë‹ˆë‹¤
- ë…ìëŠ” AI/í…Œí¬ì— ê´€ì‹¬ìˆëŠ” í•œêµ­ì–´ ì‚¬ìš©ìì…ë‹ˆë‹¤

## í•µì‹¬ ì›ì¹™
- **ì ˆëŒ€ ìš”ì•½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤** - ì›ë¬¸ì˜ ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ë²ˆì—­
- **ì›ë¬¸ êµ¬ì¡° ìœ ì§€** - ë¬¸ë‹¨, ìˆœì„œ, íë¦„ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€
- **ì¶”ê°€/ì‚­ì œ ê¸ˆì§€** - ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš© ì¶”ê°€ ê¸ˆì§€, ì›ë¬¸ ë‚´ìš© ìƒëµ ê¸ˆì§€
- **ëê¹Œì§€ ë²ˆì—­** - ì¤‘ê°„ì— ë©ˆì¶”ì§€ ë§ê³  ì›ë¬¸ ì „ì²´ë¥¼ ì™„ì „íˆ ë²ˆì—­

## ì¤‘ìš”: ê³ ìœ ëª…ì‚¬ ì²˜ë¦¬ (ë²ˆì—­ ê¸ˆì§€)
- **íšŒì‚¬ëª…**: OpenAI, Anthropic, Google, Meta, Microsoft, NVIDIA, xAI, Mistral AI, Cohere, Hugging Face ë“±
- **ì œí’ˆ/ëª¨ë¸ëª…**: GPT-4, Claude, Gemini, Llama, Mistral, Grok, DALL-E, Midjourney, Stable Diffusion ë“±
- **ì¸ëª…**: Sam Altman, Dario Amodei, Demis Hassabis, Yann LeCun, Andrej Karpathy ë“±
- **ê¸°ìˆ  ìš©ì–´**: API, GPU, TPU, transformer, fine-tuning, RAG, embedding, inference, token, context window, RLHF, LoRA ë“±

## ì¶œë ¥ í¬ë§· (Markdown)
- ì„¹ì…˜ ì œëª©ì€ ## ë˜ëŠ” ### í—¤ë”© ì‚¬ìš©
- ë¬¸ë‹¨ ì‚¬ì´ ë¹ˆ ì¤„ë¡œ êµ¬ë¶„
- ë¦¬ìŠ¤íŠ¸ëŠ” - ë˜ëŠ” 1. 2. 3. í˜•ì‹
- ì¤‘ìš” í‚¤ì›Œë“œëŠ” **ë³¼ë“œ** ì²˜ë¦¬
- ì¸ìš©ë¬¸ì€ > ì‚¬ìš©
- ì½”ë“œë‚˜ ê¸°ìˆ  ìš©ì–´ëŠ” \`backtick\` ì‚¬ìš©`;

  const userPrompt = `ë‹¤ìŒ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ìš”ì•½í•˜ì§€ ë§ê³  ì›ë¬¸ ì „ì²´ë¥¼ ëê¹Œì§€ ì¶©ì‹¤íˆ ë²ˆì—­í•˜ì„¸ìš”.

${title ? `## ${title}\n\n` : ""}${trimmedContent.substring(0, 12000)}`;

  const response = await ai.models.generateContent({
    model: MODEL,
    contents: `${systemPrompt}\n\n---\n\n${userPrompt}`,
    config: {
      temperature: 0.2,
    },
  });

  const translatedContent = response.text || trimmedContent;

  return {
    title: title || "",
    content: translatedContent,
    isTranslated: true,
  };
}

// ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ íƒ€ì…
export interface ImageGenerationResult {
  base64: string;
  mimeType: string;
  description?: string;
}

// Aspect ratioë¥¼ Gemini API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
function convertAspectRatio(aspectRatio: string): string {
  const ratioMap: Record<string, string> = {
    "16:9": "16:9",
    "1:1": "1:1",
    "4:5": "4:5",
    "9:16": "9:16",
    "1.91:1": "16:9", // LinkedIn ê·¼ì‚¬ì¹˜
    "4:3": "4:3",
    "3:4": "3:4",
  };
  return ratioMap[aspectRatio] || "1:1";
}

// ê¸°ì‚¬ ë‚´ìš© ë¶„ì„í•˜ì—¬ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
async function analyzeContentForImage(
  headline: string,
  summary: string
): Promise<string> {
  const ai = getGeminiClient();

  const analysisPrompt = `You are an expert at creating image generation prompts for news article backgrounds.

Analyze this news headline and summary, then create a specific image prompt for a BACKGROUND image.

Headline: ${headline}
Summary: ${summary}

IMPORTANT: This image will have text overlaid later. Generate a CLEAN background only.

Rules:
1. If a specific PERSON is the focus (CEO, researcher, etc.):
   - Professional portrait, centered composition
   - Leave some space at top for text overlay

2. If a COMPANY/BRAND is the focus (OpenAI, Google, Meta, etc.):
   - Feature their recognizable logo or brand colors
   - Modern, clean tech environment

3. If a PRODUCT/TECHNOLOGY is the focus:
   - Clean product visualization
   - Professional aesthetic

4. If it's an ABSTRACT CONCEPT (AI trend, market analysis, etc.):
   - Symbolic imagery, data visualizations, conceptual art
   - Modern, professional aesthetic

Output ONLY the image description in English. Be specific about:
- Main subject (centered, not at the very top)
- Environment/background
- Lighting and mood
- Colors (prefer darker/muted tones for text readability)

DO NOT include any text or typography in the image.
Keep it under 80 words. No explanations, just the prompt.`;

  const response = await ai.models.generateContent({
    model: MODEL,
    contents: analysisPrompt,
    config: {
      temperature: 0.7,
    },
  });

  return response.text || "Modern tech workspace with abstract data visualization, dark ambient lighting";
}

// AI ë‰´ìŠ¤ ì´ë¯¸ì§€ ìƒì„± (í—¤ë“œë¼ì¸ í…ìŠ¤íŠ¸ í¬í•¨)
export async function generateNewsImage(
  headline: string,
  summary: string,
  _platform: string,
  aspectRatio: string = "9:16"
): Promise<ImageGenerationResult> {
  const ai = getGeminiClient();

  // 1ë‹¨ê³„: ê¸°ì‚¬ ë‚´ìš© ë¶„ì„í•˜ì—¬ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
  const imageDescription = await analyzeContentForImage(headline, summary);

  // 2ë‹¨ê³„: í—¤ë“œë¼ì¸ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ë‰´ìŠ¤ ì¹´ë“œ ì´ë¯¸ì§€ ìƒì„±
  const prompt = `Create a professional social media news card image with the following Korean headline text displayed prominently.

HEADLINE TEXT TO DISPLAY (must appear exactly as written):
"${headline}"

BACKGROUND SCENE:
${imageDescription}

DESIGN REQUIREMENTS:
1. TEXT STYLING:
   - Display the headline text in clean, modern sans-serif font (like Pretendard or similar)
   - Text color: WHITE with subtle drop shadow for readability
   - Text position: TOP area of the image (upper 30%)
   - Text size: Large and prominent, easy to read
   - Line breaks: Keep natural line breaks if present in the headline

2. BACKGROUND:
   - The scene described above should fill the entire canvas
   - Apply a subtle dark gradient overlay at the top for text readability
   - DSLR quality, professional lighting
   - Darker or muted tones work best

3. COMPOSITION:
   - Clean, modern, professional news card aesthetic
   - The headline must be the focal point and clearly readable
   - Background should complement, not compete with the text

CRITICAL: The Korean headline text MUST be rendered correctly and be clearly readable.`;

  const geminiAspectRatio = convertAspectRatio(aspectRatio);

  const response = await ai.models.generateContent({
    model: IMAGE_MODEL,
    contents: prompt,
    config: {
      responseModalities: ["TEXT", "IMAGE"],
      imageConfig: {
        aspectRatio: geminiAspectRatio,
        imageSize: "2K",
      },
    },
  });

  // ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
  let base64 = "";
  let mimeType = "image/png";
  let description = "";

  if (response.candidates && response.candidates[0]?.content?.parts) {
    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.data) {
        base64 = part.inlineData.data;
        mimeType = part.inlineData.mimeType || "image/png";
      }
      if (part.text) {
        description = part.text;
      }
    }
  }

  if (!base64) {
    throw new Error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.");
  }

  return {
    base64,
    mimeType,
    description,
  };
}
